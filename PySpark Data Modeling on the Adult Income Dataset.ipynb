{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark_SNPIAO_with_more_documentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz2w35TQSlM3"
      },
      "source": [
        "# **Складишта на податоци и аналитичка обработка**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVzQielxPPfh"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znXJScSf-BYQ"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHgGtdNg-vIh"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\"\n",
        "os.environ[\"PATH_TO_DRIVER_JAR\"] = \"/content/sqljdbc_8.2.2.0_enu/sqljdbc_8.2/enu/mssql-jdbc-8.2.2.jre8.jar\"\n",
        "os.environ[\"PYSPARK_PYTHON\"] = 'python3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNLyoj2shqWX"
      },
      "source": [
        "## Initiate SparkContext\n",
        "\n",
        "### Main entry point for Spark functionality. A SparkContext represents the connection to a Spark cluster, and can be used to create RDDs, accumulators and broadcast variables on that cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1ucBST4_tNx"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i5xZl8lmxjM"
      },
      "source": [
        "## Initiate SQLContext\n",
        "\n",
        "### SQLContext is a class that contains several useful functions to work with Spark SQL and it is an entry point to Spark SQL. Here we also add a file to be downloaded with this Spark job on every node (the file from the URL)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vveOvVx6UfZ"
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/guru99-edu/R-Programming/master/adult_data.csv\"\n",
        "sc.addFile(url)\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RYFWvNxm9an"
      },
      "source": [
        "### Read csv file. When header is set to true the first line of files will be used to name columns and will not be included in data. All types will be assumed automatically because of inferSchema=True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyWK9bhtlwS8"
      },
      "source": [
        "df = sqlContext.read.csv(SparkFiles.get(\"adult_data.csv\"), header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5itMaP_5mhn6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "b6f3fa75-8c13-4365-afa2-7502a00fe213"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- x: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- workclass: string (nullable = true)\n",
            " |-- fnlwgt: integer (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- educational-num: integer (nullable = true)\n",
            " |-- marital-status: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- relationship: string (nullable = true)\n",
            " |-- race: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- capital-gain: integer (nullable = true)\n",
            " |-- capital-loss: integer (nullable = true)\n",
            " |-- hours-per-week: integer (nullable = true)\n",
            " |-- native-country: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmy0Y8HynKJO"
      },
      "source": [
        "See several rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95a4QFY4mvpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "91b0f428-5cc2-4d69-af61-1c9cd6b6adc5"
      },
      "source": [
        "df.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "|x  |age|workclass|fnlwgt|education   |educational-num|marital-status    |occupation       |relationship|race |gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
            "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "|1  |25 |Private  |226802|11th        |7              |Never-married     |Machine-op-inspct|Own-child   |Black|Male  |0           |0           |40            |United-States |<=50K |\n",
            "|2  |38 |Private  |89814 |HS-grad     |9              |Married-civ-spouse|Farming-fishing  |Husband     |White|Male  |0           |0           |50            |United-States |<=50K |\n",
            "|3  |28 |Local-gov|336951|Assoc-acdm  |12             |Married-civ-spouse|Protective-serv  |Husband     |White|Male  |0           |0           |40            |United-States |>50K  |\n",
            "|4  |44 |Private  |160323|Some-college|10             |Married-civ-spouse|Machine-op-inspct|Husband     |Black|Male  |7688        |0           |40            |United-States |>50K  |\n",
            "|5  |18 |?        |103497|Some-college|10             |Never-married     |?                |Own-child   |White|Female|0           |0           |30            |United-States |<=50K |\n",
            "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcqQhmaBn3C-"
      },
      "source": [
        "## Custom function to convert the data type of DataFrame columns\n",
        "### Parameters are the dataframe, the columns to be converted, and the data type to which they will be converted. For every column, we cast it to the new data type and set the same column to be with the casted values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urIT2YgZnIsI"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "def convertColumn(df, names, newType):\n",
        "    for name in names: \n",
        "        df = df.withColumn(name, df[name].cast(newType))\n",
        "    return df "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMI0J6dSoEpX"
      },
      "source": [
        "## Convert continuous features to Float"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIDBQegkn8rP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "baa5d49d-2064-4fdc-89d0-f99b288b594f"
      },
      "source": [
        "CONTINUOUS_FEATURES  = ['age', 'fnlwgt','capital-gain', 'educational-num', 'capital-loss', 'hours-per-week']\n",
        "df_string = convertColumn(df, CONTINUOUS_FEATURES, FloatType())\n",
        "df_string.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- x: integer (nullable = true)\n",
            " |-- age: float (nullable = true)\n",
            " |-- workclass: string (nullable = true)\n",
            " |-- fnlwgt: float (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- educational-num: float (nullable = true)\n",
            " |-- marital-status: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- relationship: string (nullable = true)\n",
            " |-- race: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- capital-gain: float (nullable = true)\n",
            " |-- capital-loss: float (nullable = true)\n",
            " |-- hours-per-week: float (nullable = true)\n",
            " |-- native-country: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ifG_4ZtqVy3"
      },
      "source": [
        "## Different operations we can do with the columns\n",
        "\n",
        "### Select some columns (as with SQL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zePui9KZo3Pz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4f39aa5c-02d0-45eb-aac6-9614094f185e"
      },
      "source": [
        "df.select('age','fnlwgt').show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------+\n",
            "|age|fnlwgt|\n",
            "+---+------+\n",
            "| 25|226802|\n",
            "| 38| 89814|\n",
            "| 28|336951|\n",
            "| 44|160323|\n",
            "| 18|103497|\n",
            "+---+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7cTsh52qfP0"
      },
      "source": [
        "### Count number of rows by education level and then sort by the count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP2CezD2qVJN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "0f936506-bb78-443b-e008-29c09d535818"
      },
      "source": [
        "df.groupBy(\"education\").count().sort(\"count\", ascending=True).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-----+\n",
            "|   education|count|\n",
            "+------------+-----+\n",
            "|   Preschool|   83|\n",
            "|     1st-4th|  247|\n",
            "|     5th-6th|  509|\n",
            "|   Doctorate|  594|\n",
            "|        12th|  657|\n",
            "|         9th|  756|\n",
            "| Prof-school|  834|\n",
            "|     7th-8th|  955|\n",
            "|        10th| 1389|\n",
            "|  Assoc-acdm| 1601|\n",
            "|        11th| 1812|\n",
            "|   Assoc-voc| 2061|\n",
            "|     Masters| 2657|\n",
            "|   Bachelors| 8025|\n",
            "|Some-college|10878|\n",
            "|     HS-grad|15784|\n",
            "+------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM8nRItlqxgP"
      },
      "source": [
        "### Show some descriptive statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1wi_Lu5qen2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "fe949505-0e3b-409f-ce2e-ba6a5f704e76"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+-----------------+------------------+--------------+------+\n",
            "|summary|                 x|               age|  workclass|            fnlwgt|   education|   educational-num|marital-status|      occupation|relationship|              race|gender|      capital-gain|     capital-loss|    hours-per-week|native-country|income|\n",
            "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+-----------------+------------------+--------------+------+\n",
            "|  count|             48842|             48842|      48842|             48842|       48842|             48842|         48842|           48842|       48842|             48842| 48842|             48842|            48842|             48842|         48842| 48842|\n",
            "|   mean|           24421.5| 38.64358543876172|       null|189664.13459727284|        null|10.078088530363212|          null|            null|        null|              null|  null|1079.0676262233324|87.50231358257237|40.422382375824085|          null|  null|\n",
            "| stddev|14099.615260708357|13.710509934443502|       null|105604.02542315757|        null| 2.570972755592252|          null|            null|        null|              null|  null| 7452.019057655413|403.0045521243591|12.391444024252289|          null|  null|\n",
            "|    min|                 1|                17|          ?|             12285|        10th|                 1|      Divorced|               ?|     Husband|Amer-Indian-Eskimo|Female|                 0|                0|                 1|             ?| <=50K|\n",
            "|    max|             48842|                90|Without-pay|           1490400|Some-college|                16|       Widowed|Transport-moving|        Wife|             White|  Male|             99999|             4356|                99|    Yugoslavia|  >50K|\n",
            "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+-----------------+------------------+--------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8_8DOR9q9v7"
      },
      "source": [
        "### Show descriptive statistics for specific column\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQMOWeLCqwtV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "66da3fb2-ced7-4a6e-fe6e-f400262dc275"
      },
      "source": [
        "df.describe('capital-gain').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+\n",
            "|summary|      capital-gain|\n",
            "+-------+------------------+\n",
            "|  count|             48842|\n",
            "|   mean|1079.0676262233324|\n",
            "| stddev| 7452.019057655413|\n",
            "|    min|                 0|\n",
            "|    max|             99999|\n",
            "+-------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIhEC0E1rxsh"
      },
      "source": [
        "### Cross-tabular reports are matrix-like or spreadsheet-like reports. These reports are useful for presenting summary numeric data. Here we do a Cross-tabular report between 2 pairwise columns (number of people grouped by age, with income below or above 50k) and sort the results by age. We can see that as the age increases, there are more and more people with income above 50K. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHhcvGDaq-gE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "794a4575-f206-4221-c05f-2d3538f1504e"
      },
      "source": [
        "df.crosstab('age', 'income').sort(\"age_income\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+----+\n",
            "|age_income|<=50K|>50K|\n",
            "+----------+-----+----+\n",
            "|        17|  595|   0|\n",
            "|        18|  862|   0|\n",
            "|        19| 1050|   3|\n",
            "|        20| 1112|   1|\n",
            "|        21| 1090|   6|\n",
            "|        22| 1161|  17|\n",
            "|        23| 1307|  22|\n",
            "|        24| 1162|  44|\n",
            "|        25| 1119|  76|\n",
            "|        26| 1068|  85|\n",
            "|        27| 1117| 115|\n",
            "|        28| 1101| 179|\n",
            "|        29| 1025| 198|\n",
            "|        30| 1031| 247|\n",
            "|        31| 1050| 275|\n",
            "|        32|  957| 296|\n",
            "|        33| 1045| 290|\n",
            "|        34|  949| 354|\n",
            "|        35|  997| 340|\n",
            "|        36|  948| 400|\n",
            "+----------+-----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoYQBWVDsS9m"
      },
      "source": [
        "### This is how we can drop columns if they are unnecessary (here we actually drop a column on a copy of the dataframe because it is only done as an example and we need this column)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XSFMxkVrJ0G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "751b19dd-f6d5-4b6c-e9fe-6a2821cafd67"
      },
      "source": [
        "df.drop('educational-num').columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x',\n",
              " 'age',\n",
              " 'workclass',\n",
              " 'fnlwgt',\n",
              " 'education',\n",
              " 'marital-status',\n",
              " 'occupation',\n",
              " 'relationship',\n",
              " 'race',\n",
              " 'gender',\n",
              " 'capital-gain',\n",
              " 'capital-loss',\n",
              " 'hours-per-week',\n",
              " 'native-country',\n",
              " 'income']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lq7zAIeYZpl"
      },
      "source": [
        "# Handling missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRU9yn9KcBiB"
      },
      "source": [
        "### The missing values are populated with a question mark (the string '?'). We need those values to be null so that we can use built in functions from the PySpark DataFrame API to make the handling of missing data more convenient. So we replace '?' with None."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3W-xZd1cDZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "9aef4ad6-ed01-4525-9f16-051090662ea6"
      },
      "source": [
        "df = df.replace('?', None)\n",
        "\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  x|age|       workclass|fnlwgt|   education|educational-num|    marital-status|       occupation| relationship|              race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  1| 25|         Private|226802|        11th|              7|     Never-married|Machine-op-inspct|    Own-child|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "|  2| 38|         Private| 89814|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|      Husband|             White|  Male|           0|           0|            50| United-States| <=50K|\n",
            "|  3| 28|       Local-gov|336951|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|      Husband|             White|  Male|           0|           0|            40| United-States|  >50K|\n",
            "|  4| 44|         Private|160323|Some-college|             10|Married-civ-spouse|Machine-op-inspct|      Husband|             Black|  Male|        7688|           0|            40| United-States|  >50K|\n",
            "|  5| 18|            null|103497|Some-college|             10|     Never-married|             null|    Own-child|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "|  6| 34|         Private|198693|        10th|              6|     Never-married|    Other-service|Not-in-family|             White|  Male|           0|           0|            30| United-States| <=50K|\n",
            "|  7| 29|            null|227026|     HS-grad|              9|     Never-married|             null|    Unmarried|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "|  8| 63|Self-emp-not-inc|104626| Prof-school|             15|Married-civ-spouse|   Prof-specialty|      Husband|             White|  Male|        3103|           0|            32| United-States|  >50K|\n",
            "|  9| 24|         Private|369667|Some-college|             10|     Never-married|    Other-service|    Unmarried|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "| 10| 55|         Private|104996|     7th-8th|              4|Married-civ-spouse|     Craft-repair|      Husband|             White|  Male|           0|           0|            10| United-States| <=50K|\n",
            "| 11| 65|         Private|184454|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        6418|           0|            40| United-States|  >50K|\n",
            "| 12| 36|     Federal-gov|212465|   Bachelors|             13|Married-civ-spouse|     Adm-clerical|      Husband|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 13| 26|         Private| 82091|     HS-grad|              9|     Never-married|     Adm-clerical|Not-in-family|             White|Female|           0|           0|            39| United-States| <=50K|\n",
            "| 14| 58|            null|299831|     HS-grad|              9|Married-civ-spouse|             null|      Husband|             White|  Male|           0|           0|            35| United-States| <=50K|\n",
            "| 15| 48|         Private|279724|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        3103|           0|            48| United-States|  >50K|\n",
            "| 16| 43|         Private|346189|     Masters|             14|Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            50| United-States|  >50K|\n",
            "| 17| 20|       State-gov|444554|Some-college|             10|     Never-married|    Other-service|    Own-child|             White|  Male|           0|           0|            25| United-States| <=50K|\n",
            "| 18| 43|         Private|128354|     HS-grad|              9|Married-civ-spouse|     Adm-clerical|         Wife|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "| 19| 37|         Private| 60548|     HS-grad|              9|           Widowed|Machine-op-inspct|    Unmarried|             White|Female|           0|           0|            20| United-States| <=50K|\n",
            "| 20| 40|         Private| 85019|   Doctorate|             16|Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|           0|           0|            45|          null|  >50K|\n",
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYqPNeYXYcak"
      },
      "source": [
        "### Dropping all null values. We can do this but in the process we also lose a lot of information (because the rows we drop have values in the columns that are not null)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhICe_SJYfqh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "19ec62b1-24d0-440c-a627-1d4e58f78f8f"
      },
      "source": [
        "df.na.drop().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "|  x|age|       workclass|fnlwgt|   education|educational-num|    marital-status|       occupation| relationship| race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "|  1| 25|         Private|226802|        11th|              7|     Never-married|Machine-op-inspct|    Own-child|Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "|  2| 38|         Private| 89814|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|      Husband|White|  Male|           0|           0|            50| United-States| <=50K|\n",
            "|  3| 28|       Local-gov|336951|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|      Husband|White|  Male|           0|           0|            40| United-States|  >50K|\n",
            "|  4| 44|         Private|160323|Some-college|             10|Married-civ-spouse|Machine-op-inspct|      Husband|Black|  Male|        7688|           0|            40| United-States|  >50K|\n",
            "|  6| 34|         Private|198693|        10th|              6|     Never-married|    Other-service|Not-in-family|White|  Male|           0|           0|            30| United-States| <=50K|\n",
            "|  8| 63|Self-emp-not-inc|104626| Prof-school|             15|Married-civ-spouse|   Prof-specialty|      Husband|White|  Male|        3103|           0|            32| United-States|  >50K|\n",
            "|  9| 24|         Private|369667|Some-college|             10|     Never-married|    Other-service|    Unmarried|White|Female|           0|           0|            40| United-States| <=50K|\n",
            "| 10| 55|         Private|104996|     7th-8th|              4|Married-civ-spouse|     Craft-repair|      Husband|White|  Male|           0|           0|            10| United-States| <=50K|\n",
            "| 11| 65|         Private|184454|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|White|  Male|        6418|           0|            40| United-States|  >50K|\n",
            "| 12| 36|     Federal-gov|212465|   Bachelors|             13|Married-civ-spouse|     Adm-clerical|      Husband|White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 13| 26|         Private| 82091|     HS-grad|              9|     Never-married|     Adm-clerical|Not-in-family|White|Female|           0|           0|            39| United-States| <=50K|\n",
            "| 15| 48|         Private|279724|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|White|  Male|        3103|           0|            48| United-States|  >50K|\n",
            "| 16| 43|         Private|346189|     Masters|             14|Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|           0|           0|            50| United-States|  >50K|\n",
            "| 17| 20|       State-gov|444554|Some-college|             10|     Never-married|    Other-service|    Own-child|White|  Male|           0|           0|            25| United-States| <=50K|\n",
            "| 18| 43|         Private|128354|     HS-grad|              9|Married-civ-spouse|     Adm-clerical|         Wife|White|Female|           0|           0|            30| United-States| <=50K|\n",
            "| 19| 37|         Private| 60548|     HS-grad|              9|           Widowed|Machine-op-inspct|    Unmarried|White|Female|           0|           0|            20| United-States| <=50K|\n",
            "| 21| 34|         Private|107914|   Bachelors|             13|Married-civ-spouse|     Tech-support|      Husband|White|  Male|           0|           0|            47| United-States|  >50K|\n",
            "| 22| 34|         Private|238588|Some-college|             10|     Never-married|    Other-service|    Own-child|Black|Female|           0|           0|            35| United-States| <=50K|\n",
            "| 24| 25|         Private|220931|   Bachelors|             13|     Never-married|   Prof-specialty|Not-in-family|White|  Male|           0|           0|            43|          Peru| <=50K|\n",
            "| 25| 25|         Private|205947|   Bachelors|             13|Married-civ-spouse|   Prof-specialty|      Husband|White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFa6GjmXYlxi"
      },
      "source": [
        "### Rows having more than 2 nulls are dropped when we set threshold to 2. This reduces the number of rows we drop and consequently the information we lose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRFPKW4eYtov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "2a5c3969-02f6-498d-9a75-9239f7fc19e0"
      },
      "source": [
        "df.na.drop(thresh=2).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  x|age|       workclass|fnlwgt|   education|educational-num|    marital-status|       occupation| relationship|              race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  1| 25|         Private|226802|        11th|              7|     Never-married|Machine-op-inspct|    Own-child|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "|  2| 38|         Private| 89814|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|      Husband|             White|  Male|           0|           0|            50| United-States| <=50K|\n",
            "|  3| 28|       Local-gov|336951|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|      Husband|             White|  Male|           0|           0|            40| United-States|  >50K|\n",
            "|  4| 44|         Private|160323|Some-college|             10|Married-civ-spouse|Machine-op-inspct|      Husband|             Black|  Male|        7688|           0|            40| United-States|  >50K|\n",
            "|  5| 18|            null|103497|Some-college|             10|     Never-married|             null|    Own-child|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "|  6| 34|         Private|198693|        10th|              6|     Never-married|    Other-service|Not-in-family|             White|  Male|           0|           0|            30| United-States| <=50K|\n",
            "|  7| 29|            null|227026|     HS-grad|              9|     Never-married|             null|    Unmarried|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "|  8| 63|Self-emp-not-inc|104626| Prof-school|             15|Married-civ-spouse|   Prof-specialty|      Husband|             White|  Male|        3103|           0|            32| United-States|  >50K|\n",
            "|  9| 24|         Private|369667|Some-college|             10|     Never-married|    Other-service|    Unmarried|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "| 10| 55|         Private|104996|     7th-8th|              4|Married-civ-spouse|     Craft-repair|      Husband|             White|  Male|           0|           0|            10| United-States| <=50K|\n",
            "| 11| 65|         Private|184454|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        6418|           0|            40| United-States|  >50K|\n",
            "| 12| 36|     Federal-gov|212465|   Bachelors|             13|Married-civ-spouse|     Adm-clerical|      Husband|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 13| 26|         Private| 82091|     HS-grad|              9|     Never-married|     Adm-clerical|Not-in-family|             White|Female|           0|           0|            39| United-States| <=50K|\n",
            "| 14| 58|            null|299831|     HS-grad|              9|Married-civ-spouse|             null|      Husband|             White|  Male|           0|           0|            35| United-States| <=50K|\n",
            "| 15| 48|         Private|279724|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        3103|           0|            48| United-States|  >50K|\n",
            "| 16| 43|         Private|346189|     Masters|             14|Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            50| United-States|  >50K|\n",
            "| 17| 20|       State-gov|444554|Some-college|             10|     Never-married|    Other-service|    Own-child|             White|  Male|           0|           0|            25| United-States| <=50K|\n",
            "| 18| 43|         Private|128354|     HS-grad|              9|Married-civ-spouse|     Adm-clerical|         Wife|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "| 19| 37|         Private| 60548|     HS-grad|              9|           Widowed|Machine-op-inspct|    Unmarried|             White|Female|           0|           0|            20| United-States| <=50K|\n",
            "| 20| 40|         Private| 85019|   Doctorate|             16|Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|           0|           0|            45|          null|  >50K|\n",
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mZJ4NXEYyS3"
      },
      "source": [
        "### Filling nulls with a custom value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXXuhcAsY5mA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "21a990d8-50eb-4e5a-e0a1-a3c5e184d3d6"
      },
      "source": [
        "df.na.fill('NA').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  x|age|       workclass|fnlwgt|   education|educational-num|    marital-status|       occupation| relationship|              race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  1| 25|         Private|226802|        11th|              7|     Never-married|Machine-op-inspct|    Own-child|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "|  2| 38|         Private| 89814|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|      Husband|             White|  Male|           0|           0|            50| United-States| <=50K|\n",
            "|  3| 28|       Local-gov|336951|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|      Husband|             White|  Male|           0|           0|            40| United-States|  >50K|\n",
            "|  4| 44|         Private|160323|Some-college|             10|Married-civ-spouse|Machine-op-inspct|      Husband|             Black|  Male|        7688|           0|            40| United-States|  >50K|\n",
            "|  5| 18|              NA|103497|Some-college|             10|     Never-married|               NA|    Own-child|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "|  6| 34|         Private|198693|        10th|              6|     Never-married|    Other-service|Not-in-family|             White|  Male|           0|           0|            30| United-States| <=50K|\n",
            "|  7| 29|              NA|227026|     HS-grad|              9|     Never-married|               NA|    Unmarried|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "|  8| 63|Self-emp-not-inc|104626| Prof-school|             15|Married-civ-spouse|   Prof-specialty|      Husband|             White|  Male|        3103|           0|            32| United-States|  >50K|\n",
            "|  9| 24|         Private|369667|Some-college|             10|     Never-married|    Other-service|    Unmarried|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "| 10| 55|         Private|104996|     7th-8th|              4|Married-civ-spouse|     Craft-repair|      Husband|             White|  Male|           0|           0|            10| United-States| <=50K|\n",
            "| 11| 65|         Private|184454|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        6418|           0|            40| United-States|  >50K|\n",
            "| 12| 36|     Federal-gov|212465|   Bachelors|             13|Married-civ-spouse|     Adm-clerical|      Husband|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 13| 26|         Private| 82091|     HS-grad|              9|     Never-married|     Adm-clerical|Not-in-family|             White|Female|           0|           0|            39| United-States| <=50K|\n",
            "| 14| 58|              NA|299831|     HS-grad|              9|Married-civ-spouse|               NA|      Husband|             White|  Male|           0|           0|            35| United-States| <=50K|\n",
            "| 15| 48|         Private|279724|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        3103|           0|            48| United-States|  >50K|\n",
            "| 16| 43|         Private|346189|     Masters|             14|Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            50| United-States|  >50K|\n",
            "| 17| 20|       State-gov|444554|Some-college|             10|     Never-married|    Other-service|    Own-child|             White|  Male|           0|           0|            25| United-States| <=50K|\n",
            "| 18| 43|         Private|128354|     HS-grad|              9|Married-civ-spouse|     Adm-clerical|         Wife|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "| 19| 37|         Private| 60548|     HS-grad|              9|           Widowed|Machine-op-inspct|    Unmarried|             White|Female|           0|           0|            20| United-States| <=50K|\n",
            "| 20| 40|         Private| 85019|   Doctorate|             16|Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|           0|           0|            45|            NA|  >50K|\n",
            "+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gPyrFPXZQZc"
      },
      "source": [
        "## A common transformation in statistical analysis with grouped data is to replace missing data within each group with the mean of the non-NaN values in the group.\n",
        "\n",
        "### Custom function for finding the mean of all columns we pass in as an argument. Returns a list of lists with 2 elements, the column name and the mean value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbqd1dq_ceGe"
      },
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "def mean_of_pyspark_columns(df, numeric_cols, verbose=False):\n",
        "    col_with_mean=[]\n",
        "    for col in numeric_cols:\n",
        "        mean_value = df.select(avg(df[col]))\n",
        "        avg_col = mean_value.columns[0]\n",
        "        res = mean_value.rdd.map(lambda row : row[avg_col]).collect()\n",
        "        \n",
        "        if (verbose==True): print(mean_value.columns[0], \"\\t\", res[0])\n",
        "        col_with_mean.append([col, res[0]])    \n",
        "    return col_with_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVcKfnYQc6xu"
      },
      "source": [
        "### We iterate column by column and replace the missing values with the column mean, while we leave the other values as they are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3lFTEgrcl5x"
      },
      "source": [
        "from pyspark.sql.functions import when, lit\n",
        "\n",
        "def fill_missing_with_mean(df, numeric_cols):\n",
        "    col_with_mean = mean_of_pyspark_columns(df, numeric_cols) \n",
        "    \n",
        "    for col, mean in col_with_mean:\n",
        "        df = df.withColumn(col, when(df[col].isNull()==True, \n",
        "        lit(mean)).otherwise(df[col]))\n",
        "        \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoV4Vsoqc92h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "8847af64-75a4-43ed-bf20-597c6a723edc"
      },
      "source": [
        "NUMERIC_COLS = ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "\n",
        "df = fill_missing_with_mean(df, NUMERIC_COLS)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  x| age|       workclass|  fnlwgt|   education|educational-num|    marital-status|       occupation| relationship|              race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
            "+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  1|25.0|         Private|226802.0|        11th|              7|     Never-married|Machine-op-inspct|    Own-child|             Black|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "|  2|38.0|         Private| 89814.0|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|      Husband|             White|  Male|         0.0|         0.0|          50.0| United-States| <=50K|\n",
            "|  3|28.0|       Local-gov|336951.0|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|      Husband|             White|  Male|         0.0|         0.0|          40.0| United-States|  >50K|\n",
            "|  4|44.0|         Private|160323.0|Some-college|             10|Married-civ-spouse|Machine-op-inspct|      Husband|             Black|  Male|      7688.0|         0.0|          40.0| United-States|  >50K|\n",
            "|  5|18.0|            null|103497.0|Some-college|             10|     Never-married|             null|    Own-child|             White|Female|         0.0|         0.0|          30.0| United-States| <=50K|\n",
            "|  6|34.0|         Private|198693.0|        10th|              6|     Never-married|    Other-service|Not-in-family|             White|  Male|         0.0|         0.0|          30.0| United-States| <=50K|\n",
            "|  7|29.0|            null|227026.0|     HS-grad|              9|     Never-married|             null|    Unmarried|             Black|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "|  8|63.0|Self-emp-not-inc|104626.0| Prof-school|             15|Married-civ-spouse|   Prof-specialty|      Husband|             White|  Male|      3103.0|         0.0|          32.0| United-States|  >50K|\n",
            "|  9|24.0|         Private|369667.0|Some-college|             10|     Never-married|    Other-service|    Unmarried|             White|Female|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 10|55.0|         Private|104996.0|     7th-8th|              4|Married-civ-spouse|     Craft-repair|      Husband|             White|  Male|         0.0|         0.0|          10.0| United-States| <=50K|\n",
            "| 11|65.0|         Private|184454.0|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|      6418.0|         0.0|          40.0| United-States|  >50K|\n",
            "| 12|36.0|     Federal-gov|212465.0|   Bachelors|             13|Married-civ-spouse|     Adm-clerical|      Husband|             White|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 13|26.0|         Private| 82091.0|     HS-grad|              9|     Never-married|     Adm-clerical|Not-in-family|             White|Female|         0.0|         0.0|          39.0| United-States| <=50K|\n",
            "| 14|58.0|            null|299831.0|     HS-grad|              9|Married-civ-spouse|             null|      Husband|             White|  Male|         0.0|         0.0|          35.0| United-States| <=50K|\n",
            "| 15|48.0|         Private|279724.0|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|      3103.0|         0.0|          48.0| United-States|  >50K|\n",
            "| 16|43.0|         Private|346189.0|     Masters|             14|Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|         0.0|         0.0|          50.0| United-States|  >50K|\n",
            "| 17|20.0|       State-gov|444554.0|Some-college|             10|     Never-married|    Other-service|    Own-child|             White|  Male|         0.0|         0.0|          25.0| United-States| <=50K|\n",
            "| 18|43.0|         Private|128354.0|     HS-grad|              9|Married-civ-spouse|     Adm-clerical|         Wife|             White|Female|         0.0|         0.0|          30.0| United-States| <=50K|\n",
            "| 19|37.0|         Private| 60548.0|     HS-grad|              9|           Widowed|Machine-op-inspct|    Unmarried|             White|Female|         0.0|         0.0|          20.0| United-States| <=50K|\n",
            "| 20|40.0|         Private| 85019.0|   Doctorate|             16|Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|         0.0|         0.0|          45.0|          null|  >50K|\n",
            "+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38cax4fXbcgY"
      },
      "source": [
        "## Fill missing values from categorical column with mode of the column\n",
        "\n",
        "### Custom function for finding the mode of all columns we pass in as an argument. Returns a list of lists with 2 elements, the column name and the mode value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix6dIcVjbfxs"
      },
      "source": [
        "def mode_of_pyspark_columns(df, cat_col_list, verbose=False):\n",
        "    col_with_mode=[]\n",
        "    for col in cat_col_list:\n",
        "        #Filter null\n",
        "        df = df.filter(df[col].isNull()==False)\n",
        "        #Find unique_values_with_count\n",
        "        unique_classes = df.select(col).distinct().rdd.map(lambda x: x[0]).collect()\n",
        "        unique_values_with_count=[]\n",
        "        for uc in unique_classes:\n",
        "             unique_values_with_count.append([uc, df.filter(df[col]==uc).count()])\n",
        "        #sort unique values w.r.t their count values\n",
        "        sorted_unique_values_with_count= sorted(unique_values_with_count, key = lambda x: x[1], reverse =True)\n",
        "        \n",
        "        if (verbose==True): print(col, sorted_unique_values_with_count, \" and mode is \", sorted_unique_values_with_count[0][0])\n",
        "        col_with_mode.append([col, sorted_unique_values_with_count[0][0]])\n",
        "    return col_with_mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nxYM5xtdnjj"
      },
      "source": [
        "### We iterate column by column and replace the missing values with the column mode, while we leave the other values as they are. Just like we did with the mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzwfDfeVdrLD"
      },
      "source": [
        "from pyspark.sql.functions import when, lit\n",
        "\n",
        "def fill_missing_with_mode(df, cat_col_list):\n",
        "    col_with_mode = mode_of_pyspark_columns(df, cat_col_list)\n",
        "    \n",
        "    for col, mode in col_with_mode:\n",
        "        df = df.withColumn(col, when(df[col].isNull()==True, \n",
        "        lit(mode)).otherwise(df[col]))\n",
        "        \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXgOuq5Iduhc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "03d31201-559c-4d7e-f261-81527b4d2ef3"
      },
      "source": [
        "CATE_COLS = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "\n",
        "df = fill_missing_with_mode(df, CATE_COLS)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  x| age|       workclass|  fnlwgt|   education|educational-num|    marital-status|       occupation| relationship|              race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
            "+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|  1|25.0|         Private|226802.0|        11th|              7|     Never-married|Machine-op-inspct|    Own-child|             Black|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "|  2|38.0|         Private| 89814.0|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|      Husband|             White|  Male|         0.0|         0.0|          50.0| United-States| <=50K|\n",
            "|  3|28.0|       Local-gov|336951.0|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|      Husband|             White|  Male|         0.0|         0.0|          40.0| United-States|  >50K|\n",
            "|  4|44.0|         Private|160323.0|Some-college|             10|Married-civ-spouse|Machine-op-inspct|      Husband|             Black|  Male|      7688.0|         0.0|          40.0| United-States|  >50K|\n",
            "|  5|18.0|         Private|103497.0|Some-college|             10|     Never-married|   Prof-specialty|    Own-child|             White|Female|         0.0|         0.0|          30.0| United-States| <=50K|\n",
            "|  6|34.0|         Private|198693.0|        10th|              6|     Never-married|    Other-service|Not-in-family|             White|  Male|         0.0|         0.0|          30.0| United-States| <=50K|\n",
            "|  7|29.0|         Private|227026.0|     HS-grad|              9|     Never-married|   Prof-specialty|    Unmarried|             Black|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "|  8|63.0|Self-emp-not-inc|104626.0| Prof-school|             15|Married-civ-spouse|   Prof-specialty|      Husband|             White|  Male|      3103.0|         0.0|          32.0| United-States|  >50K|\n",
            "|  9|24.0|         Private|369667.0|Some-college|             10|     Never-married|    Other-service|    Unmarried|             White|Female|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 10|55.0|         Private|104996.0|     7th-8th|              4|Married-civ-spouse|     Craft-repair|      Husband|             White|  Male|         0.0|         0.0|          10.0| United-States| <=50K|\n",
            "| 11|65.0|         Private|184454.0|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|      6418.0|         0.0|          40.0| United-States|  >50K|\n",
            "| 12|36.0|     Federal-gov|212465.0|   Bachelors|             13|Married-civ-spouse|     Adm-clerical|      Husband|             White|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 13|26.0|         Private| 82091.0|     HS-grad|              9|     Never-married|     Adm-clerical|Not-in-family|             White|Female|         0.0|         0.0|          39.0| United-States| <=50K|\n",
            "| 14|58.0|         Private|299831.0|     HS-grad|              9|Married-civ-spouse|   Prof-specialty|      Husband|             White|  Male|         0.0|         0.0|          35.0| United-States| <=50K|\n",
            "| 15|48.0|         Private|279724.0|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|      3103.0|         0.0|          48.0| United-States|  >50K|\n",
            "| 16|43.0|         Private|346189.0|     Masters|             14|Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|         0.0|         0.0|          50.0| United-States|  >50K|\n",
            "| 17|20.0|       State-gov|444554.0|Some-college|             10|     Never-married|    Other-service|    Own-child|             White|  Male|         0.0|         0.0|          25.0| United-States| <=50K|\n",
            "| 18|43.0|         Private|128354.0|     HS-grad|              9|Married-civ-spouse|     Adm-clerical|         Wife|             White|Female|         0.0|         0.0|          30.0| United-States| <=50K|\n",
            "| 19|37.0|         Private| 60548.0|     HS-grad|              9|           Widowed|Machine-op-inspct|    Unmarried|             White|Female|         0.0|         0.0|          20.0| United-States| <=50K|\n",
            "| 20|40.0|         Private| 85019.0|   Doctorate|             16|Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|         0.0|         0.0|          45.0| United-States|  >50K|\n",
            "+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJvTIGwWsYAL"
      },
      "source": [
        "### Counting number of rows filtered by some condition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFPoaY4OsUdW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88905868-1b9d-4209-b0f6-ba1e5f8b41d7"
      },
      "source": [
        "df.filter(df.age > 40).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mdJk8ADsgtU"
      },
      "source": [
        "### Descriptive statistics by group (calculate mean of data grouped by marital status) which reveals some information. We can see that people married with a person in the Armed Forced (Married-AF-spouse) have the highest capital gain. People that never married have the lowest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk9D4l2xsZaM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "e700e11d-aa79-4d4c-854c-6720f0ae3245"
      },
      "source": [
        "df.groupby('marital-status').agg({'capital-gain': 'mean'}).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------------------+\n",
            "|      marital-status| avg(capital-gain)|\n",
            "+--------------------+------------------+\n",
            "|           Separated| 581.8424836601307|\n",
            "|       Never-married|  384.382639449029|\n",
            "|Married-spouse-ab...| 629.0047770700637|\n",
            "|            Divorced| 793.6755615860094|\n",
            "|             Widowed| 603.6442687747035|\n",
            "|   Married-AF-spouse|2971.6216216216217|\n",
            "|  Married-civ-spouse|1739.7006121810625|\n",
            "+--------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyF2fVi9tIGs"
      },
      "source": [
        "## Create new features from existing ones\n",
        "\n",
        "### Age is not a linear function with the income. When people are young, their income is usually lower than mid-age. After retirement, a household uses their saving, meaning a decrease in income. To capture this pattern, we add a square to the age feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLgDdwussrKw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "39d41080-0d0c-40ed-b9d5-b2e0f6b965f0"
      },
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "df = df.withColumn(\"age_square\", col(\"age\") ** 2)\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- x: integer (nullable = true)\n",
            " |-- age: double (nullable = true)\n",
            " |-- workclass: string (nullable = true)\n",
            " |-- fnlwgt: double (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- educational-num: integer (nullable = true)\n",
            " |-- marital-status: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- relationship: string (nullable = true)\n",
            " |-- race: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- capital-gain: double (nullable = true)\n",
            " |-- capital-loss: double (nullable = true)\n",
            " |-- hours-per-week: double (nullable = true)\n",
            " |-- native-country: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            " |-- age_square: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKT9LJdOzp90"
      },
      "source": [
        "### Check row count for every country and sort them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYGqpnf8tsAV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "689db6c8-a5bb-485e-dc06-4a5dc8096443"
      },
      "source": [
        "df.groupby('native-country').agg({'native-country': 'count'}).sort(asc(\"count(native-country)\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+---------------------+\n",
            "|      native-country|count(native-country)|\n",
            "+--------------------+---------------------+\n",
            "|  Holand-Netherlands|                    1|\n",
            "|             Hungary|                   19|\n",
            "|            Honduras|                   20|\n",
            "|            Scotland|                   21|\n",
            "|Outlying-US(Guam-...|                   23|\n",
            "|                Laos|                   23|\n",
            "|          Yugoslavia|                   23|\n",
            "|     Trinadad&Tobago|                   27|\n",
            "|            Cambodia|                   28|\n",
            "|                Hong|                   30|\n",
            "|            Thailand|                   30|\n",
            "|             Ireland|                   37|\n",
            "|              France|                   38|\n",
            "|             Ecuador|                   45|\n",
            "|                Peru|                   46|\n",
            "|              Greece|                   49|\n",
            "|           Nicaragua|                   49|\n",
            "|                Iran|                   59|\n",
            "|              Taiwan|                   65|\n",
            "|            Portugal|                   67|\n",
            "+--------------------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL4nGHHSzu4E"
      },
      "source": [
        "### Holand-Netherlands has only 1 observation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV5k_nAVzXUZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb8b3cef-552a-4a70-e07b-00fd26f776c7"
      },
      "source": [
        "df.filter(df['native-country'] == 'Holand-Netherlands').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdGnTuB2z2Fx"
      },
      "source": [
        "### When a group within a feature has only one observation, it brings no information to the model. On the contrary, it can lead to an errors, so we remove that row (and group)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygqazg5dzybZ"
      },
      "source": [
        "df = df.filter(df['native-country'] != 'Holand-Netherlands')\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5P8jMyaU-sB"
      },
      "source": [
        "# Infering new Fields (rank, lag, moving avg) for the Covid-19 cases in Germany!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMBPFFePce_g"
      },
      "source": [
        "\"\"\"\n",
        "===== For the following examples, the covid_de.csv file is used =====\n",
        "#contains more numerical data\n",
        "#has a \"data\" column\n",
        "\"\"\"\n",
        "df_covid = sqlContext.read.csv(SparkFiles.get(\"/content/covid_de.csv\"), header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQNfVFO_coug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "0ddfbce6-c7f4-4085-fb32-17c7c64ec947"
      },
      "source": [
        "#columns\n",
        "df_covid.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- state: string (nullable = true)\n",
            " |-- county: string (nullable = true)\n",
            " |-- age_group: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- cases: integer (nullable = true)\n",
            " |-- deaths: integer (nullable = true)\n",
            " |-- recovered: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWJzmU_QenGt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "5d3bfe04-1c58-4eae-d4bd-61bbb8283a24"
      },
      "source": [
        "#first 20 rows\n",
        "df_covid.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+------------------+---------+------+----------+-----+------+---------+\n",
            "|             state|            county|age_group|gender|      date|cases|deaths|recovered|\n",
            "+------------------+------------------+---------+------+----------+-----+------+---------+\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    00-04|     F|2020-03-27|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    00-04|     F|2020-03-28|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    00-04|     F|2020-04-03|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    00-04|     M|2020-04-05|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    00-04|     M|2020-05-18|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    00-04|     M|2020-07-27|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    00-04|     M|2020-08-12|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    00-04|     M|2020-08-23|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    00-04|     M|2020-09-20|    1|     0|        0|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-03-17|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-03-25|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-03-26|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-03-29|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-03-31|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-04-01|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-04-09|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-04-17|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-04-27|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-05-11|    1|     0|        1|\n",
            "|Baden-Wuerttemberg|LK Alb-Donau-Kreis|    05-14|     F|2020-05-23|    1|     0|        1|\n",
            "+------------------+------------------+---------+------+----------+-----+------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbWPHUQjVpwn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "f81b23ca-a2cd-4262-afa0-eab40230c2a8"
      },
      "source": [
        "from pyspark.sql.window import Window # for initialising the sliding window\n",
        "from pyspark.sql import functions as F # module containing some basic sql functionalities\n",
        "\n",
        "\"\"\"\n",
        "== pyspark.sql.functions.rank() \n",
        "== This gives you the ranking within your ordered partition.\n",
        "== Ties are assigned the same rank, with the next ranking/s skipped\n",
        "\"\"\"\n",
        "#The rank for the number of cases, partitioned by the GENDER\n",
        "windowSpec = Window().partitionBy(['gender']).orderBy(F.desc('cases'))\n",
        "df_covid.withColumn(\"rank\",F.rank().over(windowSpec)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+---------+------+----------+-----+------+---------+----+\n",
            "|              state|              county|age_group|gender|      date|cases|deaths|recovered|rank|\n",
            "+-------------------+--------------------+---------+------+----------+-----+------+---------+----+\n",
            "|             Bayern|         SK Muenchen|    35-59|     F|2020-03-26|   64|     0|       64|   1|\n",
            "|             Bayern|         SK Muenchen|    35-59|     F|2020-03-31|   60|     1|       59|   2|\n",
            "|Nordrhein-Westfalen|       LK Guetersloh|    35-59|     F|2020-06-17|   56|     0|       56|   3|\n",
            "|             Bayern|         SK Muenchen|    15-34|     F|2020-03-25|   54|     0|       54|   4|\n",
            "|             Bayern|         SK Muenchen|    35-59|     F|2020-03-25|   54|     0|       54|   4|\n",
            "|             Bayern|         SK Muenchen|    15-34|     F|2020-03-31|   52|     0|       52|   6|\n",
            "|             Bayern|         SK Muenchen|    35-59|     F|2020-03-27|   52|     0|       52|   6|\n",
            "| Baden-Wuerttemberg|       LK Reutlingen|    80-99|     F|2020-04-12|   47|    11|       36|   8|\n",
            "|             Bayern|LK Dingolfing-Landau|    35-59|     F|2020-08-04|   45|     0|       45|   9|\n",
            "|            Hamburg|          SK Hamburg|    35-59|     F|2020-04-07|   45|     0|       45|   9|\n",
            "|             Bayern|         SK Muenchen|    15-34|     F|2020-03-27|   44|     0|       44|  11|\n",
            "|            Hamburg|          SK Hamburg|    35-59|     F|2020-03-19|   44|     0|       44|  11|\n",
            "|             Bayern|         SK Muenchen|    15-34|     F|2020-03-21|   43|     0|       43|  13|\n",
            "|             Bayern|LK Dingolfing-Landau|    35-59|     F|2020-08-10|   42|     0|       42|  14|\n",
            "|             Bayern|         SK Muenchen|    15-34|     F|2020-03-26|   42|     0|       42|  14|\n",
            "|             Bayern|         SK Muenchen|    15-34|     F|2020-09-15|   42|     0|       10|  14|\n",
            "|             Bayern|         SK Muenchen|    35-59|     F|2020-03-18|   42|     0|       42|  14|\n",
            "|             Bayern|         SK Muenchen|    15-34|     F|2020-09-16|   41|     0|        3|  18|\n",
            "| Baden-Wuerttemberg|        LK Tuebingen|    35-59|     F|2020-03-24|   40|     0|       40|  19|\n",
            "|             Bayern|         SK Muenchen|    35-59|     F|2020-04-01|   40|     0|       40|  19|\n",
            "+-------------------+--------------------+---------+------+----------+-----+------+---------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPgCPA-2Z4-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "95802d2f-f0d6-4d25-f01f-992aeac73bcf"
      },
      "source": [
        "\"\"\"\n",
        "== pyspark.sql.functions.lag()\n",
        "== fetches data from previous rows\n",
        "== finding trends\n",
        "== infering new dimensions for classification/regression\n",
        "\"\"\"\n",
        "#Computing the lag with 7 days difference\n",
        "windowSpec = Window().partitionBy(['state']).orderBy('date')\n",
        "dfWithLag = df_covid.withColumn(\"lag_week\",F.lag(\"cases\", 7).over(windowSpec))\n",
        "dfWithLag.filter(dfWithLag.date>'2020-03-11').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+---------+------+----------+-----+------+---------+--------+\n",
            "|         state|              county|age_group|gender|      date|cases|deaths|recovered|lag_week|\n",
            "+--------------+--------------------+---------+------+----------+-----+------+---------+--------+\n",
            "|Sachsen-Anhalt|LK Altmarkkreis S...|    15-34|     M|2020-03-12|    1|     0|        1|       2|\n",
            "|Sachsen-Anhalt|LK Anhalt-Bitterfeld|    15-34|     M|2020-03-12|    1|     0|        1|       2|\n",
            "|Sachsen-Anhalt|           LK Boerde|    60-79|     M|2020-03-12|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|             LK Harz|    35-59|     F|2020-03-12|    1|     0|        1|       2|\n",
            "|Sachsen-Anhalt|             LK Harz|    35-59|     M|2020-03-12|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    35-59|     M|2020-03-12|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|       LK Wittenberg|    15-34|     F|2020-03-12|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|       LK Wittenberg|    35-59|     F|2020-03-12|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     F|2020-03-12|    2|     0|        2|       1|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     M|2020-03-12|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     F|2020-03-12|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    15-34|     F|2020-03-12|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    35-59|     F|2020-03-12|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|  LK Burgenlandkreis|    35-59|     M|2020-03-13|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|  LK Jerichower Land|    60-79|     M|2020-03-13|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    35-59|     M|2020-03-13|    1|     0|        1|       2|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     F|2020-03-13|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     F|2020-03-13|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     M|2020-03-13|    1|     0|        1|       1|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    15-34|     F|2020-03-13|    1|     0|        1|       1|\n",
            "+--------------+--------------------+---------+------+----------+-----+------+---------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS3TT-o8fB6T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "2cc9f78f-ca27-49d7-e96c-bdbfae51d73c"
      },
      "source": [
        "\"\"\"\n",
        "== pyspark.sql.functions.lead()\n",
        "== fetches data from subsequent rows\n",
        "== finding trends\n",
        "== infering new dimensions for classification/regression\n",
        "\"\"\"\n",
        "#computing lead with approximately 1 month period\n",
        "windowSpec = Window().partitionBy(['state']).orderBy('date')\n",
        "dfWithLag = df_covid.withColumn(\"lead_month\",F.lead(\"cases\", 31).over(windowSpec))\n",
        "dfWithLag.filter(dfWithLag.date>'2020-03-11').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+---------+------+----------+-----+------+---------+----------+\n",
            "|         state|              county|age_group|gender|      date|cases|deaths|recovered|lead_month|\n",
            "+--------------+--------------------+---------+------+----------+-----+------+---------+----------+\n",
            "|Sachsen-Anhalt|LK Altmarkkreis S...|    15-34|     M|2020-03-12|    1|     0|        1|         2|\n",
            "|Sachsen-Anhalt|LK Anhalt-Bitterfeld|    15-34|     M|2020-03-12|    1|     0|        1|         5|\n",
            "|Sachsen-Anhalt|           LK Boerde|    60-79|     M|2020-03-12|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|             LK Harz|    35-59|     F|2020-03-12|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|             LK Harz|    35-59|     M|2020-03-12|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    35-59|     M|2020-03-12|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|       LK Wittenberg|    15-34|     F|2020-03-12|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|       LK Wittenberg|    35-59|     F|2020-03-12|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     F|2020-03-12|    2|     0|        2|         1|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     M|2020-03-12|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     F|2020-03-12|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    15-34|     F|2020-03-12|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    35-59|     F|2020-03-12|    1|     0|        1|         2|\n",
            "|Sachsen-Anhalt|  LK Burgenlandkreis|    35-59|     M|2020-03-13|    1|     0|        1|         2|\n",
            "|Sachsen-Anhalt|  LK Jerichower Land|    60-79|     M|2020-03-13|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    35-59|     M|2020-03-13|    1|     0|        1|         2|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     F|2020-03-13|    1|     0|        1|         2|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     F|2020-03-13|    1|     0|        1|         1|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     M|2020-03-13|    1|     0|        1|         2|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    15-34|     F|2020-03-13|    1|     0|        1|         1|\n",
            "+--------------+--------------------+---------+------+----------+-----+------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5K-e9LLelXK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "1ed27447-8fd8-4796-b105-5a02bc90ea97"
      },
      "source": [
        "\"\"\"\n",
        "== pyspark.sql.functions.mean()\n",
        "== returns the avg value of a column\n",
        "== if .rowsBetween() is not specified, it finds the whole mean\n",
        "== if it is specified .rowsBetween(a,b) then,\n",
        "a rolling window with a rows before the observed row and b rows\n",
        "after the observed row are taken into consideration in\n",
        "calculating the mean\n",
        "\"\"\"\n",
        "#moving avarage including 6 days around the observed day + itself\n",
        "windowSpec = Window().partitionBy(['state']).orderBy('date').rowsBetween(-3,3)\n",
        "dfWithRoll = df_covid.withColumn(\"roll_7_cases\",F.mean(\"cases\").over(windowSpec))\n",
        "dfWithRoll.filter(dfWithLag.date>'2020-03-11').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+---------+------+----------+-----+------+---------+------------------+\n",
            "|         state|              county|age_group|gender|      date|cases|deaths|recovered|      roll_7_cases|\n",
            "+--------------+--------------------+---------+------+----------+-----+------+---------+------------------+\n",
            "|Sachsen-Anhalt|LK Altmarkkreis S...|    15-34|     M|2020-03-12|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|LK Anhalt-Bitterfeld|    15-34|     M|2020-03-12|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|           LK Boerde|    60-79|     M|2020-03-12|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|             LK Harz|    35-59|     F|2020-03-12|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|             LK Harz|    35-59|     M|2020-03-12|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    35-59|     M|2020-03-12|    1|     0|        1|1.1428571428571428|\n",
            "|Sachsen-Anhalt|       LK Wittenberg|    15-34|     F|2020-03-12|    1|     0|        1|1.1428571428571428|\n",
            "|Sachsen-Anhalt|       LK Wittenberg|    35-59|     F|2020-03-12|    1|     0|        1|1.1428571428571428|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     F|2020-03-12|    2|     0|        2|1.1428571428571428|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     M|2020-03-12|    1|     0|        1|1.1428571428571428|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     F|2020-03-12|    1|     0|        1|1.1428571428571428|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    15-34|     F|2020-03-12|    1|     0|        1|1.1428571428571428|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    35-59|     F|2020-03-12|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|  LK Burgenlandkreis|    35-59|     M|2020-03-13|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|  LK Jerichower Land|    60-79|     M|2020-03-13|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    35-59|     M|2020-03-13|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     F|2020-03-13|    1|     0|        1|               1.0|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     F|2020-03-13|    1|     0|        1|1.1428571428571428|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     M|2020-03-13|    1|     0|        1|1.1428571428571428|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    15-34|     F|2020-03-13|    1|     0|        1|1.1428571428571428|\n",
            "+--------------+--------------------+---------+------+----------+-----+------+---------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnNPBzQwglbx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "2106606b-114c-4b0b-de80-dfb9f535bed8"
      },
      "source": [
        "\"\"\"\n",
        "== pyspark.sql.functions.sum()\n",
        "== same functionalities with the mean function\n",
        "== .rowsBetween(Window.unboundedPreceding,Window.currentRow)\n",
        "is taken so it sums all the cases to the observed day\n",
        "\"\"\"\n",
        "#cumulative number of cases per state, ordered by the date\n",
        "windowSpec = Window().partitionBy(['state']).orderBy('date').rowsBetween(Window.unboundedPreceding,Window.currentRow)\n",
        "dfWithRoll = df_covid.withColumn(\"cumulative_cases\",F.sum(\"cases\").over(windowSpec))\n",
        "dfWithRoll.filter(dfWithLag.date>'2020-03-01').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+---------+------+----------+-----+------+---------+----------------+\n",
            "|         state|              county|age_group|gender|      date|cases|deaths|recovered|cumulative_cases|\n",
            "+--------------+--------------------+---------+------+----------+-----+------+---------+----------------+\n",
            "|Sachsen-Anhalt|  LK Burgenlandkreis|    60-79|     F|2020-03-10|    1|     0|        1|               1|\n",
            "|Sachsen-Anhalt|       LK Saalekreis|    60-79|     F|2020-03-10|    1|     0|        1|               2|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    35-59|     M|2020-03-10|    1|     0|        1|               3|\n",
            "|Sachsen-Anhalt|            SK Halle|    15-34|     M|2020-03-10|    1|     0|        1|               4|\n",
            "|Sachsen-Anhalt|            SK Halle|    35-59|     M|2020-03-10|    1|     0|        1|               5|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    60-79|     M|2020-03-10|    1|     0|        1|               6|\n",
            "|Sachsen-Anhalt|LK Anhalt-Bitterfeld|    15-34|     M|2020-03-11|    1|     0|        1|               7|\n",
            "|Sachsen-Anhalt|           LK Boerde|    35-59|     M|2020-03-11|    2|     0|        2|               9|\n",
            "|Sachsen-Anhalt|LK Mansfeld-Suedharz|    35-59|     M|2020-03-11|    1|     0|        1|              10|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    35-59|     F|2020-03-11|    1|     0|        1|              11|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    60-79|     F|2020-03-11|    2|     0|        2|              13|\n",
            "|Sachsen-Anhalt|    LK Salzlandkreis|    60-79|     M|2020-03-11|    2|     0|        2|              15|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     F|2020-03-11|    1|     0|        1|              16|\n",
            "|Sachsen-Anhalt|            SK Halle|    60-79|     M|2020-03-11|    2|     1|        1|              18|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    15-34|     F|2020-03-11|    1|     0|        1|              19|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    15-34|     M|2020-03-11|    1|     0|        1|              20|\n",
            "|Sachsen-Anhalt|        SK Magdeburg|    35-59|     M|2020-03-11|    1|     0|        1|              21|\n",
            "|Sachsen-Anhalt|LK Altmarkkreis S...|    15-34|     M|2020-03-12|    1|     0|        1|              22|\n",
            "|Sachsen-Anhalt|LK Anhalt-Bitterfeld|    15-34|     M|2020-03-12|    1|     0|        1|              23|\n",
            "|Sachsen-Anhalt|           LK Boerde|    60-79|     M|2020-03-12|    1|     0|        1|              24|\n",
            "+--------------+--------------------+---------+------+----------+-----+------+---------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05HaB0WbjBtT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "778fec0c-b03e-4261-9449-6bd59c88bd45"
      },
      "source": [
        "\"\"\"\n",
        "pandas.DataFrame.rollup()\n",
        "== get the distribution of cases for each state\n",
        "and each county in that state separately \n",
        "\"\"\"\n",
        "# rollup for the number of cases in one state and in the counties separately\n",
        "df_covid.rollup(df_covid['state'],df_covid['county']).sum('cases').sort('state','county').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+--------------------+----------+\n",
            "|             state|              county|sum(cases)|\n",
            "+------------------+--------------------+----------+\n",
            "|              null|                null|    278043|\n",
            "|Baden-Wuerttemberg|                null|     47879|\n",
            "|Baden-Wuerttemberg|  LK Alb-Donau-Kreis|       877|\n",
            "|Baden-Wuerttemberg|         LK Biberach|       777|\n",
            "|Baden-Wuerttemberg|    LK Bodenseekreis|       522|\n",
            "|Baden-Wuerttemberg|       LK Boeblingen|      2047|\n",
            "|Baden-Wuerttemberg|LK Breisgau-Hochs...|      1443|\n",
            "|Baden-Wuerttemberg|             LK Calw|       890|\n",
            "|Baden-Wuerttemberg|      LK Emmendingen|       671|\n",
            "|Baden-Wuerttemberg|         LK Enzkreis|       834|\n",
            "|Baden-Wuerttemberg|        LK Esslingen|      2585|\n",
            "|Baden-Wuerttemberg|     LK Freudenstadt|       656|\n",
            "|Baden-Wuerttemberg|       LK Goeppingen|      1138|\n",
            "|Baden-Wuerttemberg|       LK Heidenheim|       614|\n",
            "|Baden-Wuerttemberg|        LK Heilbronn|      1319|\n",
            "|Baden-Wuerttemberg|   LK Hohenlohekreis|       843|\n",
            "|Baden-Wuerttemberg|        LK Karlsruhe|      1356|\n",
            "|Baden-Wuerttemberg|         LK Konstanz|       733|\n",
            "|Baden-Wuerttemberg|         LK Loerrach|       865|\n",
            "|Baden-Wuerttemberg|      LK Ludwigsburg|      2523|\n",
            "+------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhjvWDTG02Vm"
      },
      "source": [
        "## Encoding categorical variables with OneHot Encoding method\n",
        "\n",
        "### One-hot encoding maps a categorical feature, represented as a label index, to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values. This encoding allows algorithms which expect continuous features, such as Logistic Regression, to use categorical features. For string type input data, it is common to encode categorical features using StringIndexer first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUb3DPWe0I0J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "f8bfdf82-c377-482d-8244-df3504f5c680"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "\n",
        "stringIndexer = StringIndexer(inputCol=\"workclass\", outputCol=\"workclass_encoded\")\n",
        "model = stringIndexer.fit(df)\n",
        "indexed = model.transform(df)\n",
        "encoder = OneHotEncoder(dropLast=False, inputCol=\"workclass_encoded\", outputCol=\"workclass_vec\")\n",
        "encoded = encoder.fit(indexed).transform(indexed)\n",
        "encoded.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----+---------+--------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+----------+-----------------+-------------+\n",
            "|  x| age|workclass|  fnlwgt|   education|educational-num|    marital-status|       occupation|relationship| race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|age_square|workclass_encoded|workclass_vec|\n",
            "+---+----+---------+--------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+----------+-----------------+-------------+\n",
            "|  1|25.0|  Private|226802.0|        11th|              7|     Never-married|Machine-op-inspct|   Own-child|Black|  Male|         0.0|         0.0|          40.0| United-States| <=50K|     625.0|              0.0|(8,[0],[1.0])|\n",
            "|  2|38.0|  Private| 89814.0|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|     Husband|White|  Male|         0.0|         0.0|          50.0| United-States| <=50K|    1444.0|              0.0|(8,[0],[1.0])|\n",
            "|  3|28.0|Local-gov|336951.0|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|     Husband|White|  Male|         0.0|         0.0|          40.0| United-States|  >50K|     784.0|              2.0|(8,[2],[1.0])|\n",
            "|  4|44.0|  Private|160323.0|Some-college|             10|Married-civ-spouse|Machine-op-inspct|     Husband|Black|  Male|      7688.0|         0.0|          40.0| United-States|  >50K|    1936.0|              0.0|(8,[0],[1.0])|\n",
            "|  5|18.0|  Private|103497.0|Some-college|             10|     Never-married|   Prof-specialty|   Own-child|White|Female|         0.0|         0.0|          30.0| United-States| <=50K|     324.0|              0.0|(8,[0],[1.0])|\n",
            "+---+----+---------+--------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+----------+-----------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piEBhHh4v4qr"
      },
      "source": [
        "## We will now build the pipeline which will consist of 5 steps:\n",
        "### 1. encoding the categorical data\n",
        "### 2. indexing the label feature\n",
        "### 3. Adding continuous variable\n",
        "### 4. Assemble the steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fym3HAo13oz"
      },
      "source": [
        "### Next we encode all categorical features (previous cell was an example for one column only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlOHJ95pHGNs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1c652771-3443-43dc-b214-8d920e22ca6e"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- x: integer (nullable = true)\n",
            " |-- age: double (nullable = true)\n",
            " |-- workclass: string (nullable = true)\n",
            " |-- fnlwgt: double (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- educational-num: integer (nullable = true)\n",
            " |-- marital-status: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- relationship: string (nullable = true)\n",
            " |-- race: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- capital-gain: double (nullable = true)\n",
            " |-- capital-loss: double (nullable = true)\n",
            " |-- hours-per-week: double (nullable = true)\n",
            " |-- native-country: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            " |-- age_square: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhgxSHtkvna4"
      },
      "source": [
        "### We index all categorical columns with the StringIndexer. StringIndexer encodes a string column of labels to a column of label indices. StringIndexer can encode multiple columns. The indices are in [0, numLabels). Next we One-Hot encode the indexed columns. We add these 2 stages in the pipeline for all columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDCeTngI1Ocg"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "\n",
        "CATE_FEATURES = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "stages = [] # stages in our Pipeline\n",
        "\n",
        "for categoricalCol in CATE_FEATURES:\n",
        "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
        "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()],\n",
        "                            outputCols=[categoricalCol + \"classVec\"])\n",
        "    stages += [stringIndexer, encoder]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvozW1aO-19o"
      },
      "source": [
        "### Indexing the target variable(income)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVFnfjn7wluH"
      },
      "source": [
        "label_stringIdx =  StringIndexer(inputCol=\"income\", outputCol=\"newincome\")\n",
        "stages += [label_stringIdx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YNJnMfn_mSk"
      },
      "source": [
        "### Adding the continuous variables to the input for the VectorAssembler. VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaV3M_8L_eUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "7f396250-88d1-492e-8da6-62622dbd0150"
      },
      "source": [
        "assemblerInputs = [c + \"classVec\" for c in CATE_FEATURES] + CONTINUOUS_FEATURES\n",
        "\n",
        "assemblerInputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['workclassclassVec',\n",
              " 'educationclassVec',\n",
              " 'marital-statusclassVec',\n",
              " 'occupationclassVec',\n",
              " 'relationshipclassVec',\n",
              " 'raceclassVec',\n",
              " 'genderclassVec',\n",
              " 'native-countryclassVec',\n",
              " 'age',\n",
              " 'fnlwgt',\n",
              " 'capital-gain',\n",
              " 'educational-num',\n",
              " 'capital-loss',\n",
              " 'hours-per-week']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmUUVoaGBA0K"
      },
      "source": [
        "### We add the Assembler to the pipeline stages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_OK7kZq_vg6"
      },
      "source": [
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "stages += [assembler]\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XOKYyzpBMha"
      },
      "source": [
        "### We create the pipeline. MLlib standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline, or workflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3msQBp36BDkL"
      },
      "source": [
        "pipeline = Pipeline(stages=stages)\n",
        "pipelineModel = pipeline.fit(df)\n",
        "model = pipelineModel.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfiHYJeGBN9q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7c7c1228-6b9e-40ce-98da-23f1a04e2dec"
      },
      "source": [
        "model.take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(x=1, age=25.0, workclass='Private', fnlwgt=226802.0, education='11th', educational-num=7, marital-status='Never-married', occupation='Machine-op-inspct', relationship='Own-child', race='Black', gender='Male', capital-gain=0.0, capital-loss=0.0, hours-per-week=40.0, native-country='United-States', income='<=50K', age_square=625.0, workclassIndex=0.0, workclassclassVec=SparseVector(7, {0: 1.0}), educationIndex=5.0, educationclassVec=SparseVector(15, {5: 1.0}), marital-statusIndex=1.0, marital-statusclassVec=SparseVector(6, {1: 1.0}), occupationIndex=6.0, occupationclassVec=SparseVector(13, {6: 1.0}), relationshipIndex=2.0, relationshipclassVec=SparseVector(5, {2: 1.0}), raceIndex=1.0, raceclassVec=SparseVector(4, {1: 1.0}), genderIndex=0.0, genderclassVec=SparseVector(1, {0: 1.0}), native-countryIndex=0.0, native-countryclassVec=SparseVector(39, {0: 1.0}), newincome=0.0, features=SparseVector(96, {0: 1.0, 12: 1.0, 23: 1.0, 34: 1.0, 43: 1.0, 47: 1.0, 50: 1.0, 51: 1.0, 90: 25.0, 91: 226802.0, 93: 7.0, 95: 40.0}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRGx-LEoBZiR"
      },
      "source": [
        "## Building the classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WydhXrQBpym"
      },
      "source": [
        "### For faster computation we convert the model to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLFvsqSMBR4R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "a5513323-6c0e-4ddd-da46-78df3b3c8649"
      },
      "source": [
        "from pyspark.ml.linalg import DenseVector\n",
        "\n",
        "input_data = model.rdd.map(lambda x: (x[\"newincome\"], DenseVector(x[\"features\"])))\n",
        "df_train = sqlContext.createDataFrame(input_data, [\"income\", \"features\"])\n",
        "\n",
        "df_train.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|income|            features|\n",
            "+------+--------------------+\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   1.0|[0.0,0.0,1.0,0.0,...|\n",
            "|   1.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   1.0|[0.0,1.0,0.0,0.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   1.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   1.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   1.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,1.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
            "|   1.0|[1.0,0.0,0.0,0.0,...|\n",
            "+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-beGDtsCHQ4"
      },
      "source": [
        "### Split the dataset to train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkRy-hL0Bfod"
      },
      "source": [
        "df_train = df_train.cache()\n",
        "train_data, test_data = df_train.randomSplit([.8,.2], seed=43)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8lFaB3BHpje",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "31b64376-5b2b-4951-c8cb-b22a141b217c"
      },
      "source": [
        "train_data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|income|            features|\n",
            "+------+--------------------+\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "|   0.0|[0.0,0.0,0.0,0.0,...|\n",
            "+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2yQTtz6COIr"
      },
      "source": [
        "### Count how many people there are with income below/above 50k in both training and test set. We inspect this to see if the sets are severely unbalanced which is not the case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYB8K5VuCL4_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "109224f0-24b3-40a6-d428-b0224df4990d"
      },
      "source": [
        "train_data.groupby('income').agg({'income': 'count'}).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------+\n",
            "|income|count(income)|\n",
            "+------+-------------+\n",
            "|   0.0|        29823|\n",
            "|   1.0|         9360|\n",
            "+------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cef_7fH4CSbN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "8207feb5-30c2-4d02-d07d-9eaca6211cb0"
      },
      "source": [
        "test_data.groupby('income').agg({'income': 'count'}).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------+\n",
            "|income|count(income)|\n",
            "+------+-------------+\n",
            "|   0.0|         7331|\n",
            "|   1.0|         2327|\n",
            "+------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnGvVf12F-xn"
      },
      "source": [
        "## Building the logistic regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqJ5_ekHF84R"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(labelCol=\"income\",\n",
        "                        featuresCol=\"features\",\n",
        "                        maxIter=10,\n",
        "                        regParam=0.3)\n",
        "\n",
        "linearModel = lr.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcfoT8d5GKnh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "433e07c8-9471-4cd0-e10a-745e1fae264f"
      },
      "source": [
        "print(\"Coefficients: \" + str(linearModel.coefficients))\n",
        "print(\"Intercept: \" + str(linearModel.intercept))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: [-0.12863364737077815,-0.18156806522743066,-0.04011268487727221,-0.11184537380290616,0.13213474349308152,0.1866422680189497,-0.27219432777404845,-0.19851434232830123,-0.07817198008047521,0.22194275665196056,0.4024938302207757,-0.01680811784852384,-0.3145732573558494,-0.00929292020184624,-0.33608778224610486,-0.43699620705411746,0.582673291996581,-0.3935466022217571,-0.25802623651736734,0.626310030431398,-0.3584820060218133,-0.37760875525077325,0.3261633636266663,-0.3567986728235619,-0.19882153370674402,-0.20364462403810552,-0.1743333724220145,-0.1263040224593002,0.05955406759367189,-0.06058544108354798,0.2911608786861292,-0.12514190916745033,0.03952099426009896,-0.28550335022504864,-0.20182952013358166,-0.10953164250024859,-0.2925047964648147,-0.2979915731048789,0.09660487829940864,0.09734375537174352,-0.2792302660252221,0.2731507597582963,-0.19648115257313148,-0.301806393536135,-0.24566737167384553,0.393287654596328,-0.07134665951519187,-0.17958908989355912,-0.08058429476202071,-0.2939154570027705,0.16571370568841995,-0.17244207085313534,-0.3945800481363955,-0.05166330937349411,-0.13981663214228618,-0.3138079458981503,-0.04843691695782101,-0.27557429202957834,-0.16627661689572523,-0.18566167863080713,-0.009746833844594698,-0.23649977275816728,-0.40286330849098845,-0.21552278983904397,-0.000720063134397082,-0.43863439320234526,-0.06338609971381894,-0.31664909354361254,-0.21210222272609192,-0.48136244273515494,-0.5443479587772688,-0.20323873936729572,-0.18442139826304482,-0.03977752361256171,-0.18936523619883555,-0.14885905388713658,-0.42095608791782935,-0.34409840141038095,-0.3450279337234272,0.06400441930120976,0.2934938426595454,-0.1183540499687641,-0.2573597006370345,-0.1386409554326197,-0.5226579994507975,-0.48777240647666814,-0.4423316439472624,0.10274724645306417,-0.4396030137294922,-0.2227932344254364,0.005826343325588937,8.669933433099019e-08,2.1163045824667862e-05,0.026917830073537072,0.00021769411412492638,0.008427651514489518]\n",
            "Intercept: -1.8204749276501708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ool3sselJi1Y"
      },
      "source": [
        "### We predict the values of the target variable in the test set. Next we evaluate the model by commonly used metrics such as accuracy and area under the ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WGvBfNdJf_t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "742ba0af-9a2c-428f-89c2-85cf886a293b"
      },
      "source": [
        "predictions = linearModel.transform(test_data)\n",
        "predictions.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- income: double (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuFFkoCFxd_P"
      },
      "source": [
        "### We see the actual values and the obtained predictions and the probabilities associated with the predicted values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv6en-bLJrfx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "dc202612-1885-4982-ce6b-6e0a22990e88"
      },
      "source": [
        "selected = predictions.select(\"income\", \"prediction\", \"probability\")\n",
        "selected.show(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----------+--------------------+\n",
            "|income|prediction|         probability|\n",
            "+------+----------+--------------------+\n",
            "|   0.0|       0.0|[0.89266953321816...|\n",
            "|   0.0|       0.0|[0.90112462964047...|\n",
            "|   0.0|       0.0|[0.87226367190461...|\n",
            "|   0.0|       0.0|[0.94709055173955...|\n",
            "|   0.0|       0.0|[0.92235587448879...|\n",
            "|   0.0|       0.0|[0.75499160720068...|\n",
            "|   0.0|       0.0|[0.64682247958949...|\n",
            "|   0.0|       0.0|[0.89693809880161...|\n",
            "|   0.0|       0.0|[0.88648295030040...|\n",
            "|   0.0|       1.0|[0.44112817660515...|\n",
            "|   0.0|       0.0|[0.88906834120282...|\n",
            "|   0.0|       0.0|[0.88716899294267...|\n",
            "|   0.0|       0.0|[0.84065909307684...|\n",
            "|   0.0|       0.0|[0.87941782877909...|\n",
            "|   0.0|       0.0|[0.85191091812879...|\n",
            "|   0.0|       0.0|[0.68702019613462...|\n",
            "|   0.0|       0.0|[0.86161527231472...|\n",
            "|   0.0|       0.0|[0.82374352560222...|\n",
            "|   0.0|       0.0|[0.59278596452410...|\n",
            "|   0.0|       0.0|[0.55667153466019...|\n",
            "+------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlchzghMKD44"
      },
      "source": [
        "### Check the number of instances of a class in the label and the prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbdKxCQJulh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d4baadde-3f3c-4c88-ef39-6c924175894b"
      },
      "source": [
        "cm = predictions.select(\"income\", \"prediction\")\t\n",
        "cm.groupby('income').agg({'income': 'count'}).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------+\n",
            "|income|count(income)|\n",
            "+------+-------------+\n",
            "|   0.0|         7331|\n",
            "|   1.0|         2327|\n",
            "+------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_cxy-MkJ817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "dc0f6f41-a556-41f6-ea8a-1dbf80f97683"
      },
      "source": [
        "cm.groupby('prediction').agg({'prediction': 'count'}).show()\t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----------------+\n",
            "|prediction|count(prediction)|\n",
            "+----------+-----------------+\n",
            "|       0.0|             8786|\n",
            "|       1.0|              872|\n",
            "+----------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSsV13EdKJ6_"
      },
      "source": [
        "### The accuracy of a machine learning classification algorithm is one way to measure how often the algorithm classifies a data point correctly. We can compute the accuracy by computing the count when the label are correctly classified over the total number of rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eXOHQzEKAiZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47b77fe9-87ab-43d6-ebf5-df62f3b6f69f"
      },
      "source": [
        "cm.filter(cm.income == cm.prediction).count() / cm.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8153862083247049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieonDwMxKUgl"
      },
      "source": [
        "### We can wrap previous steps in a function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-zyWNBiKMWA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96ff3ef9-760d-4057-cef6-6b715c47d670"
      },
      "source": [
        "def accuracy_m(model): \n",
        "    predictions = model.transform(test_data)\n",
        "    cm = predictions.select(\"income\", \"prediction\")\n",
        "    acc = cm.filter(cm.income == cm.prediction).count() / cm.count()\n",
        "    print(\"Model accuracy: %.3f%%\" % (acc * 100)) \n",
        "\n",
        "accuracy_m(model = linearModel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy: 81.539%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfn58nvWKfyc"
      },
      "source": [
        "## ROC metrics\n",
        "### The Receiver Operating Characteristic curve is another common tool used with binary classification. It is very similar to the precision/recall curve, but instead of plotting precision versus recall, the ROC curve shows the true positive rate (i.e. recall) against the false positive rate. The false positive rate is the ratio of negative instances that are incorrectly classified as positive. It is equal to one minus the true negative rate. The true negative rate is also called specificity. Hence the ROC curve plots sensitivity (recall) versus 1 - specificity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d42xwFnfKXrR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8f062fed-ef56-4ed8-c9c6-c69c72b1605a"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "#change income column name to label\n",
        "predictions = predictions.withColumnRenamed(\"income\", \"label\")\n",
        "print(evaluator.evaluate(predictions))\n",
        "print(evaluator.getMetricName())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8900027005897135\n",
            "areaUnderROC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY0XwLbLLan9"
      },
      "source": [
        "## Tuning hyperparameters\n",
        "### Hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters are learned. The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_vjsvyqLUim",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a49edf0f-2725-4517-f20c-1afda6ffa96b"
      },
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Create ParamGrid for Cross Validation\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(lr.regParam, [0.01, 0.5])\n",
        "             .build())\n",
        "\n",
        "from time import *\n",
        "\n",
        "start_time = time()\n",
        "\n",
        "# Create 5-fold CrossValidator\n",
        "cv = CrossValidator(estimator=lr,\n",
        "                    estimatorParamMaps=paramGrid,\n",
        "                    evaluator=evaluator, \n",
        "                    numFolds=5)\n",
        "train_data = train_data.withColumn(\"label\", col(\"income\"))\n",
        "# Run cross validations\n",
        "cvModel = cv.fit(train_data)\n",
        "end_time = time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Time to train model: {elapsed_time} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to train model: 42.0366473197937 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iIlnriPyp5B"
      },
      "source": [
        "### We see the accuracy of the model with optimal hyperparameters which is a bit better (by 3%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no1ZrAQdLumT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "237c5aef-cd46-4071-ae93-8bcbb4e87182"
      },
      "source": [
        "accuracy_m(model = cvModel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy: 84.479%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keLUQ77My2Wy"
      },
      "source": [
        "### We can see all of the parameters of the model with optimal hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jknjzcO7PEk3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "6dfa1904-e4e4-463d-afb2-d82e04d0ebd6"
      },
      "source": [
        "bestModel = cvModel.bestModel\n",
        "bestModel.extractParamMap()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Param(parent='LogisticRegression_edc4546ae281', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2,\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0,\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto',\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='featuresCol', doc='features column name.'): 'features',\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='fitIntercept', doc='whether to fit an intercept term.'): True,\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='labelCol', doc='label column name.'): 'income',\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability',\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction',\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='standardization', doc='whether to standardize the training features before fitting the model.'): True,\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5,\n",
              " Param(parent='LogisticRegression_edc4546ae281', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIpEZHiVPJh5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}